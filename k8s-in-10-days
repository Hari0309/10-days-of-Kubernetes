                                                  MASTER K8S IN TEN DAYS WITH HARI POUDEL

Day 1: Introduction to Kubernetes

Concepts and Architecture:

Kubernetes: Kubernetes is an open-source container orchestration platform for automating the deployment, scaling, and management of containerized applications.
Pod: The smallest deployable unit in Kubernetes, which can contain one or more containers.
Node: A worker machine in the Kubernetes cluster where Pods run.
Control Plane: The cluster's brain, consisting of components like the API Server, Scheduler, and Controller Manager.
Architecture: Understand the high-level architecture of Kubernetes, with Nodes forming the cluster and the Control Plane managing it.
Installation:

Set up a local Kubernetes cluster using a tool like Minikube. If you haven't already installed Minikube, do so first.

# Install Minikube "FOLLOW MY K8S ALL IN ONE REPO FOR INSTALLATION PROCESS"
minikube start
minikube status
#############################################################################################        

                        KUBECTL

kubectl is the command-line tool used to interact with Kubernetes clusters. Learn some fundamental commands:

To get the list of nodes in your cluster:
kubectl get nodes
To get more information about a specific node:
kubectl describe node <node_name>

                        
                                    Deploying Your First Pod:

Create a simple YAML file to define a Pod. For example, create a file named my-pod.yaml with the following content:

yaml
Copy code
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: my-container
    image: nginx:latest

This YAML file defines a Pod named my-pod with a single container based on the Nginx image.

Use kubectl to create the Pod from your YAML file:

kubectl apply -f my-pod.yaml
Verify that the Pod is running:

kubectl get pods
You should see your my-pod in the list with the status "Running."

Congratulations! You've successfully set up a local Kubernetes cluster, learned basic kubectl commands, and deployed your first Pod. This is just the beginning of your Kubernetes journey. Continue to explore more advanced topics and use cases in the following days.

#############################################################################################################################
                                                DAY 2 0F K8S

Certainly! On Day 2, you'll dive deeper into using kubectl and understand more about Deployments, 
ReplicaSets, and creating your first Deployment.

                                           ReplicaSets and Deployments:

ReplicaSets: Understand that ReplicaSets are responsible for maintaining a specified number of Pod replicas. If a Pod goes down, the ReplicaSet ensures it's replaced.
Deployments: Deployments are higher-level abstractions that manage ReplicaSets and provide declarative updates to applications.


                                           Master more kubectl commands:

To view the details of a Deployment:
# kubectl describe deployment <deployment_name>

To view logs from a Pod:
# kubectl logs <pod_name>

To access a shell inside a Pod:
#kubectl exec -it <pod_name> -- /bin/bash


                                               Creating Deployments:

Create a Deployment YAML file named my-deployment.yaml:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-container
        image: nginx:latest

This YAML file defines a Deployment named my-deployment with three replicas, each running an Nginx container.

#kubectl apply -f my-deployment.yaml

Verify the Deployment and its Pods:
#kubectl get deployment my-deployment
#kubectl get pods -l app=my-app

Scale the Deployment to five replicas:
#kubectl scale deployment my-deployment --replicas=5


############################################################################################################################


                                              DAY 2 0F K8S  Deployments in Detail AND ADVANCED 

A Deployment in Kubernetes is a higher-level resource designed to manage ReplicaSets, which in turn manage Pods. 
Deployments provide a declarative way to describe the desired state of an application, 
and Kubernetes ensures that the actual state matches the desired state.


                                                Key Components of a Deployment:

Replicas: The replicas field in the Deployment specification determines how many identical Pods should be running at any given time. 
This allows for easy scaling up or down.

Selector: The selector field is used to identify which Pods are managed by the Deployment. 
It selects Pods based on labels.

Template: Inside the template section, you define the Pod template used for creating new Pods when scaling or updating.
It includes metadata like labels and the container specification.

                                                         Creating a Deployment:

Create a YAML File: To create a Deployment, you define its desired state in a YAML file. Here's a breakdown of the YAML file we discussed earlier:

yaml
Copy code
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-container
        image: nginx:latest
apiVersion and kind specify that this is a Deployment.

metadata includes metadata like the Deployment name.

spec defines the desired state.

replicas: 3 specifies that you want three replicas.

selector defines how Pods are selected using labels.

template specifies the Pod template, including labels and container specifications.

Apply the YAML File: Use the kubectl apply command to create the Deployment based on the YAML file:
kubectl apply -f my-deployment.yaml
Understanding the Deployment:

View Deployment Details: You can use the kubectl describe command to view detailed information about the Deployment:

kubectl describe deployment my-deployment
This command provides insights into the current status, events, and conditions of the Deployment.

Scaling the Deployment: Use kubectl scale to adjust the number of replicas:


kubectl scale deployment my-deployment --replicas=5
This command increases the number of replicas to five. Kubernetes will automatically manage the desired number of Pods for you


##################################################################################################################################


                                                    Day 3: ReplicaSets, Services, and Networking


ReplicaSets are Kubernetes resources that ensure a specified number of replicas (Pods) are running at all times. 
They are often managed by higher-level controllers like Deployments.
ReplicaSets use a selector to match Pods that they should manage based on labels.


Creating a ReplicaSet:

Create a YAML File: To create a ReplicaSet, define its desired state in a YAML file. Here's an example:

yaml
Copy code
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: my-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-container
        image: nginx:latest


Apply the YAML File: Use kubectl apply to create the ReplicaSet:

# kubectl apply -f my-replicaset.yaml

                                        Services in Detail:

Services provide network access to a set of Pods in Kubernetes. They allow Pods to communicate with each other and provide a stable endpoint for external traffic.
Different Service types include ClusterIP, NodePort, and LoadBalancer.
Creating a Service:

Create a YAML File: Define a Service in a YAML file. Here's an example of a ClusterIP Service:

yaml
Copy code
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: my-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80

Apply the YAML File: Use kubectl apply to create the Service:
#kubectl apply -f my-service.yaml

                                                  Advanced Networking Concepts:


Network Policies: Network Policies are used to define rules that control the flow of network traffic to and from Pods.
They allow you to enforce fine-grained network access controls within the cluster.


                                                    Creating a Network Policy:

Create a YAML File: Define a Network Policy in a YAML file. Here's an example that allows traffic only from Pods labeled as app: my-app:

yaml
Copy code
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: my-network-policy
spec:
  podSelector:
    matchLabels:
      app: my-app
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: db

Apply the YAML File: Use kubectl apply to create the Network Policy:
#kubectl apply -f my-network-policy.yaml


######################################################################################################################################
                                                                  DAY 4 OF K8S Persistent Storage in Kubernetes

                                                     Persistent Volumes (PVs):

Persistent Volumes (PVs) in Kubernetes represent physical storage resources such as a disk, SSD, or network-attached storage (NAS).
PVs are cluster-wide and can be dynamically provisioned or pre-allocated by the cluster administrator.
They exist independently of any Pod, and they must be manually claimed by creating a Persistent Volume Claim (PVC).
Persistent Volume Claims (PVCs):

Persistent Volume Claims (PVCs) are requests made by Pods for a specific amount of storage with particular access modes (e.g., ReadWriteOnce, ReadWriteMany, ReadOnlyMany).
PVCs are used to consume PVs, providing a way for Pods to access and use persistent storage in a controlled manner.
Creating a Persistent Volume (PV):

Create a PV YAML File: Define a Persistent Volume in a YAML file. Here's an example for a PV using a hostPath:

yaml
Copy code
apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /mnt/data

Apply the YAML File: Use kubectl apply to create the Persistent Volume:
#kubectl apply -f my-pv.yaml

Creating a Persistent Volume Claim (PVC):

Create a PVC YAML File: Define a Persistent Volume Claim in a YAML file. Here's an example:

yaml
Copy code
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi

#kubectl apply -f my-pvc.yaml
                                                    Binding a PVC to a PV:

Once a PVC is created, it needs to be bound to a compatible PV. Kubernetes automatically binds a PVC to an available PV that meets the PVC's requirements.
Using the PVC in a Pod:

To use the PVC in a Pod, you define the PVC as a volume in the Pod's YAML file and mount it to a specific path in the container.
Example Pod YAML with PVC:

yaml
Copy code
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  volumes:
  - name: my-volume
    persistentVolumeClaim:
      claimName: my-pvc
  containers:
  - name: my-container
    image: nginx:latest
    volumeMounts:
    - mountPath: /data
      name: my-volume

#############################################################################################################################################

                                                                         Day 5 OF K8S  StatefulSets and ConfigMaps/Secrets

StatefulSets in Brief:

StatefulSets are a type of workload resource in Kubernetes used for managing stateful applications.
They are used for applications where each Pod has a unique identity and stable network identity.
StatefulSets are often used for databases, messaging queues, and distributed systems.
Key Features of StatefulSets:

Ordered Pod creation and deletion.
Stable network identity for each Pod.
Automatic hostname and PVC provisioning.
Scaled operations to automate scaling of the cluster.
Creating a StatefulSet:

To create a StatefulSet, you define its desired state in a YAML file similar to Deployments and ReplicaSets. However, StatefulSets require additional configuration for ordered and stable naming.
ConfigMaps and Secrets in Brief:

ConfigMaps are used to decouple configuration data from Pods. They allow you to store configuration settings as key-value pairs.
Secrets are similar to ConfigMaps but are specifically designed for storing sensitive data such as passwords and API keys.
Creating a ConfigMap:

Define a ConfigMap in a YAML file and use it to inject configuration data into Pods.
Creating a Secret:

Define a Secret in a YAML file and use it to inject sensitive data securely into Pods.
Using ConfigMaps/Secrets in Pods:

#############################################################################################################################
                                                          Day 6 OF K8S  Advanced Networking and Monitoring/Logging

Advanced Networking Concepts:

Network Policies in Kubernetes:

Network Policies allow you to define rules that control the flow of network traffic to and from Pods. They provide a way to enforce fine-grained network access controls within the cluster.
Network Policies are essential for securing communication between Pods and enforcing security best practices.
Creating a Network Policy:

Create a Network Policy YAML File: Define a Network Policy in a YAML file. Here's an example:

apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: my-network-policy
spec:
  podSelector:
    matchLabels:
      app: my-app
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: db

#kubectl apply -f my-network-policy.yaml
                                                                         Monitoring and Logging:

Monitoring with Prometheus and Grafana:

Prometheus is an open-source monitoring and alerting toolkit designed for reliability and scalability.
Grafana is a platform for creating interactive and customizable dashboards that can visualize Prometheus metrics.
Setting up Prometheus and Grafana:

Install Prometheus Operator: You can use the Prometheus Operator to simplify the deployment and management of Prometheus and Grafana.
#kubectl apply -f https://raw.githubusercontent.com/coreos/prometheus-operator/master/bundle.yaml

Create Prometheus Instance: Define a Prometheus instance in a YAML file. This instance will scrape metrics from your cluster.

yaml
Copy code
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: my-prometheus
spec:
  serviceMonitorSelector:
    matchLabels:
      k8s-app: prometheus-operator
  resources:
    requests:
      memory: "400Mi"
  alerting:
    alertmanagers:
    - name: alertmanager-main
      namespace: default
      port: web
Apply the YAML File: Use kubectl apply to create the Prometheus instance:
#kubectl apply -f my-prometheus.yaml

Set Up Grafana: Install Grafana and configure it to connect to your Prometheus instance. You can use Helm for this.

Centralized Logging with EFK Stack:

The EFK stack (Elasticsearch, Fluentd, Kibana) is a popular choice for centralized logging in Kubernetes.
Setting up EFK Stack:

Install Elasticsearch, Fluentd, and Kibana: You can use Helm charts to deploy these components into your cluster.

Configure Fluentd: Set up Fluentd to collect logs from your cluster and forward them to Elasticsearch.

Access Logs in Kibana: Use Kibana to visualize and search logs.

########################################################################################################
Day 7 OF K8S    Kubernetes Networking and RBAC (Role-Based Access Control)

Kubernetes Networking:

Network Policies in Kubernetes:

Network Policies are used to define rules that control the flow of network traffic to and from Pods. They provide a way to enforce fine-grained network access controls within the cluster.
Creating a Network Policy:

Create a Network Policy YAML File: Define a Network Policy in a YAML file. Here's an example:

yaml
Copy code
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: my-network-policy
spec:
  podSelector:
    matchLabels:
      app: my-app
  ingress:
  - from:
    - podSelector:
        matchLabels:
          role: db

#kubectl apply -f my-network-policy.yaml
                                    
                                                      Role-Based Access Control (RBAC):

RBAC in Kubernetes:

Role-Based Access Control (RBAC) is a Kubernetes feature that allows you to control who can access and perform actions on resources in the cluster.
RBAC uses roles and role bindings to define permissions and grant access to users and service accounts.
Creating Roles and Role Bindings:

Create a Role YAML File: Define a Role in a YAML file. Here's an example:

yaml
Copy code
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-role
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]

#kubectl apply -f my-role.yaml


Create a Role Binding YAML File: Define a Role Binding in a YAML file to bind the Role to a user, group, or service account. Here's an example:

yaml
Copy code
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-role-binding
subjects:
- kind: User
  name: my-user
roleRef:
  kind: Role
  name: my-role
  
#kubectl apply -f my-role-binding.yaml

###############################################################################################################################

                                               Day 8 OF K8S  Kubernetes Ingress and Secrets Management

Kubernetes Ingress:

What is Ingress?

Ingress is an API object in Kubernetes that manages external access to services within the cluster. It allows you to define routing rules for HTTP and HTTPS traffic to different services based on hostnames and paths.
Setting Up Ingress:

Install an Ingress Controller: To use Ingress, you need to have an Ingress controller running in your cluster. Popular controllers include Nginx Ingress, Traefik, and HAProxy Ingress.

For example, to install Nginx Ingress using Helm:

helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install my-nginx-ingress ingress-nginx/ingress-nginx

Create an Ingress Resource: Define an Ingress resource in a YAML file. Here's an example:

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-ingress
spec:
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /app
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80

Apply the Ingress YAML File: Use kubectl apply to create the Ingress resource:

#kubectl apply -f my-ingress.yaml
                                                                Secrets Management:

Using Kubernetes Secrets:

Kubernetes Secrets are used to store and manage sensitive information, such as API keys, passwords, and TLS certificates.
Creating a Secret:

Create a Secret YAML File: Define a Secret in a YAML file. Here's an example for a TLS secret:

yaml
Copy code
apiVersion: v1
kind: Secret
metadata:
  name: my-tls-secret
type: kubernetes.io/tls
data:
  tls.crt: <base64-encoded-certificate>
  tls.key: <base64-encoded-private-key>

#kubectl apply -f my-tls-secret.yaml



#############################################################################################################################################################
                                                                  K8S DAY 8 IN ADVANCED

                                                                 Using Secrets in Pods:

To use a Secret in a Pod, reference it in your Pod's YAML file and mount it as a volume or set environment variables.




Day 8: Kubernetes Ingress and Secrets Management

Kubernetes Ingress:

What is Ingress?

Ingress is an API object in Kubernetes that manages external access to services within the cluster. It acts as a traffic controller, allowing you to define rules for routing HTTP and HTTPS traffic to different services based on hostnames and paths.
Setting Up Ingress:

Install an Ingress Controller: You need an Ingress controller to use Ingress resources. Popular options include Nginx Ingress, Traefik, and HAProxy Ingress. 
Installing an Ingress controller depends on the choice you make. For example, to install Nginx Ingress with Helm:

helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install my-nginx-ingress ingress-nginx/ingress-nginx

Create an Ingress Resource: Define an Ingress resource in a YAML file. 
This resource specifies the routing rules for incoming traffic. Here's an example:

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-ingress
spec:
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /app
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80

Apply the Ingress YAML File: Use kubectl apply to create the Ingress resource:
#kubectl apply -f my-ingress.yaml
                                                                Secrets Management:

Using Kubernetes Secrets:

Kubernetes Secrets are used for storing and managing sensitive information, such as API keys, passwords, and TLS certificates.
Creating a Secret:

Create a Secret YAML File: Define a Secret in a YAML file. Here's an example for a TLS secret:
apiVersion: v1
kind: Secret
metadata:
  name: my-tls-secret
type: kubernetes.io/tls
data:
  tls.crt: <base64-encoded-certificate>
  tls.key: <base64-encoded-private-key>
#kubectl apply -f my-tls-secret.yaml
                                                                        

#########################################################################################################################################


                                                                                Day 9 OF K8S  Helm - Kubernetes Package Manager

What is Helm?

Helm is a package manager for Kubernetes that allows you to define, install, and upgrade even the most complex Kubernetes applications. Helm packages are called "charts," and they encapsulate all the resources and configurations needed to run an application.
Using Helm:

                                                       1. Installing Helm:

You can install Helm on your local machine by following the instructions for your specific operating system: Helm Installation Guide.

                                                2. Creating a Helm Chart:

Helm charts are templates for Kubernetes resources and configuration files. 
You can create a Helm chart for your application using the helm create command. For example:
#helm create my-chart
This command generates a directory structure with predefined files for your chart.

                                                                3. Defining Chart Values:

Helm charts often contain values that can be customized during installation. 
These values are defined in a values.yaml file within your chart and can be overridden when installing the chart.

                                                             4. Packaging a Chart:

To package your chart into a distributable archive, use the helm package command:
#helm package my-chart
This creates a .tgz file, which is your Helm chart package.

                                                            5. Repository Setup:

Helm charts can be hosted in a repository for easy distribution. 
You can create your own repository or use a public one. To add a repository, use the helm repo add command:
#helm repo add my-repo https://example.com/my-repo
                                                          6. Installing a Chart:

To install a Helm chart, use the helm install command, specifying the release name and the chart location:
#helm install my-release my-repo/my-chart

                                                          7. Upgrading a Chart:

You can upgrade a Helm release to a new version of your application or chart using the helm upgrade command:
#helm upgrade my-release my-repo/my-chart
                                                           8. Removing a Release:

To uninstall a release and remove all associated resources, use the helm uninstall command:
#helm uninstall my-release


Real-Time Example:

Let's say you have a microservices-based application with multiple Kubernetes resources, such as Deployments, Services, and ConfigMaps. 
By creating a Helm chart for your application, you can:

Package all these resources and configurations into a single Helm chart.
Define values in the values.yaml file for customizing your application's behavior.
Host your Helm chart in a repository for easy distribution to your team or the broader community.
Use Helm to install, upgrade, and manage your application across different environments, such as development, testing, and production.
Helm simplifies the deployment and management of your Kubernetes applications, making it a valuable tool for DevOps engineers and developers working with Kubernetes.



###########################################################################################################################################3

                                                     Day 10: Kubernetes Operators

What are Kubernetes Operators?

Kubernetes Operators are custom controllers that extend the Kubernetes API to automate the management of complex, stateful applications. They are built using the Kubernetes extension API and can perform tasks like provisioning, scaling, and updating application instances.
Using Kubernetes Operators:

                                                          1. Operator Framework Installation:

Start by installing the Operator Framework, a toolkit that helps you build, test, and package Operators:
# Install Operator SDK
brew install operator-sdk
                                                         
                                                                    2. Creating an Operator:

You can create a new Operator using the operator-sdk init command. 
For example, let's say you want to create an Operator for managing a PostgreSQL database:
operator-sdk init my-postgresql-operator --domain=example.com --repo=github.com/example/postgresql-operator
                                                                    
                                                                3. Defining Custom Resources (CRs):

Operators work with Custom Resources (CRs) to define the desired state of an application. 
In the case of PostgreSQL, you might define a CR for a PostgreSQL instance with specific configuration options.

                                                                         4. Implementing Operator Logic:

In your Operator code, you'll define the reconciliation logic. 
This logic ensures that the current state of the application matches the desired state defined in the CRs.

                                                                      5. Building and Deploying the Operator:

Build your Operator using the operator-sdk build command, create a Docker image, and push it to a container registry.

                                                                    6. Deploying the Operator:

Deploy the Operator to your Kubernetes cluster. This will watch for new CRs and perform the necessary actions to reconcile the application state.

                                                               7. Creating Custom Resources:

Define a Custom Resource (CR) for PostgreSQL, specifying details like version, size, and configuration.
                    
                                                                 8. Managing the Application:

 Once the Operator is running, you can create instances of PostgreSQL by creating CRs. For example:

apiVersion: example.com/v1alpha1
kind: PostgreSQL
metadata:
  name: my-postgresql
spec:
  version: 13
  size: Small

Real-Time Example:

Suppose you're managing a Kubernetes cluster that hosts multiple applications, including a PostgreSQL database. Without an Operator, you'd need to manually handle tasks like scaling the database, updating it to a new version, and handling backup and restore procedures.

With a PostgreSQL Operator in place:

You define a Custom Resource (CR) for PostgreSQL, specifying the version, size, and other configuration details.
The Operator watches for this CR and automatically provisions a PostgreSQL database with the specified configuration.
When you need to scale the database, you create or modify the CR, and the Operator handles the scaling process.
When a new PostgreSQL version is released, you update the CR with the desired version, and the Operator performs the update.
This automation reduces manual intervention, ensures consistency, and simplifies the management of complex, stateful applications like databases in Kubernetes.

By the end of Day 10, you'll understand how Kubernetes Operators work and their benefits 
in automating the management of complex applications within a Kubernetes cluster

FOLLOW MY GITHUB ACCOUNT FOR MORE INFORMATION Hari0309
